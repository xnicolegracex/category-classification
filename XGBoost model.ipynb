{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Phase"
      ],
      "metadata": {
        "id": "IrZPT-xGhZCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the first Excel file\n",
        "data = pd.read_excel('train.xlsx')\n",
        "\n",
        "# Select 'Entity Title' as the feature and 'Category' as the target variable\n",
        "X = data['Entity Title']\n",
        "y = data['Category']\n",
        "\n",
        "# Label encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "lsbNovTZg_8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert text data into numerical vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_valid_vectorized = vectorizer.transform(X_valid)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Evaluate on the validation set\n",
        "y_pred_valid = xgb_model.predict(X_valid_vectorized)\n",
        "accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay_6-tGxhJGD",
        "outputId": "6d69238e-e031-491b-b727-5e8c3b2aab8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8053097345132744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the entity titles and actual categories for the validation set\n",
        "entity_titles_valid = X_valid.reset_index(drop=True)\n",
        "actual_categories_valid = label_encoder.inverse_transform(y_valid)\n",
        "\n",
        "# Inverse transform the predicted categories for the validation set\n",
        "predicted_categories_valid = label_encoder.inverse_transform(y_pred_valid)\n",
        "\n",
        "# Create a DataFrame to store predicted and actual categories for validation\n",
        "validation_results = pd.DataFrame({\n",
        "    'Entity Title': entity_titles_valid,\n",
        "    'Predicted Category': predicted_categories_valid,\n",
        "    'Actual Category': actual_categories_valid\n",
        "})\n",
        "\n",
        "# Save the validation results to an Excel file\n",
        "validation_results.to_excel('validation_results.xlsx', index=False)\n",
        "\n",
        "# Load validation results\n",
        "validation_results = pd.read_excel('validation_results.xlsx')\n",
        "\n",
        "# Filter rows where predicted category is different from actual category\n",
        "wrong_predictions = validation_results[validation_results['Predicted Category'] != validation_results['Actual Category']]\n",
        "\n",
        "# Save the wrongly predicted categories to a new Excel file\n",
        "wrong_predictions.to_excel('wrong_predictions.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "djWCzCzeiD7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "155 out of 750 wrong prediction.\n",
        "28 out of 155 are in BM"
      ],
      "metadata": {
        "id": "sdlCpp-wG7hV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVHZ3YAZcXCQ",
        "outputId": "a1f88c92-2a0d-4396-a05d-87f5ff06aa2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[  1   0   1   0   0   0]\n",
            " [  0  29   2   0   0   5]\n",
            " [  0   0 333   2   2  37]\n",
            " [  0   1  15  61   0   6]\n",
            " [  0   0  17   0  24   3]\n",
            " [  0   3  56   4   1 147]]\n",
            "\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "      Anti Corruption       1.00      0.50      0.67         2\n",
            "               ESG/ET       0.88      0.81      0.84        36\n",
            "           Functional       0.79      0.89      0.83       374\n",
            "                  HSE       0.91      0.73      0.81        83\n",
            "           Leadership       0.89      0.55      0.68        44\n",
            "Technical/Engineering       0.74      0.70      0.72       211\n",
            "\n",
            "             accuracy                           0.79       750\n",
            "            macro avg       0.87      0.70      0.76       750\n",
            "         weighted avg       0.80      0.79      0.79       750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Load the saved predictions and actual categories from the Excel file\n",
        "results_df = pd.read_excel('validation_results.xlsx')\n",
        "\n",
        "# Extract predicted and actual categories\n",
        "predicted_categories = results_df['Predicted Category']\n",
        "actual_categories = results_df['Actual Category']\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(actual_categories, predicted_categories)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(actual_categories, predicted_categories)\n",
        "\n",
        "# Display confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Phase\n",
        "\n"
      ],
      "metadata": {
        "id": "Vzydh0EqhMuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(xgb_model, 'xgb_model.pkl')\n",
        "\n",
        "# Load the trained model when needed\n",
        "loaded_model = joblib.load('xgb_model.pkl')\n"
      ],
      "metadata": {
        "id": "eroXmtJ-hKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on New Data"
      ],
      "metadata": {
        "id": "KhK1uelmhgjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the second Excel file\n",
        "new_data = pd.read_excel('test.xlsx')\n",
        "\n",
        "# Use the trained model to predict categories for new data\n",
        "X_new = new_data['Entity Title']\n",
        "X_new_vectorized = vectorizer.transform(X_new)\n",
        "predictions = loaded_model.predict(X_new_vectorized)\n",
        "\n",
        "# Inverse transform the predictions to get original category labels\n",
        "predicted_categories = label_encoder.inverse_transform(predictions)\n",
        "new_data['Predicted Category'] = predicted_categories\n",
        "\n",
        "# Save the predictions to a new Excel file\n",
        "new_data.to_excel('predicted_categories.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "vsDZlXR_hjo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrZqJzdvlu2A",
        "outputId": "97051fb9-996e-4ac1-d7d3-ddcd96fbb432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted_categories.xlsx  test.xlsx   validation_results.xlsx\txgb_model.pkl\n",
            "sample_data\t\t   train.xlsx  wrong_predictions.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune"
      ],
      "metadata": {
        "id": "S07yK86Hzlil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_excel('learning.xlsx')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data['Entity Title']\n",
        "y = data['Category']\n",
        "\n",
        "# Label encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data into numerical vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_valid_vectorized = vectorizer.transform(X_valid)\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Define the hyperparameters to tune and their respective ranges\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.3, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Perform Grid Search Cross-Validation\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the model using the best hyperparameters\n",
        "best_xgb_model = XGBClassifier(**best_params)\n",
        "best_xgb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Evaluate on the validation set\n",
        "y_pred_valid = best_xgb_model.predict(X_valid_vectorized)\n",
        "accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "print(f\"Validation Accuracy with Best Hyperparameters: {accuracy}\")\n",
        "\n",
        "# Save the validation results to an Excel file\n",
        "entity_titles_valid = X_valid.reset_index(drop=True)\n",
        "actual_categories_valid = label_encoder.inverse_transform(y_valid)\n",
        "predicted_categories_valid = label_encoder.inverse_transform(y_pred_valid)\n",
        "\n",
        "validation_results = pd.DataFrame({\n",
        "    'Entity Title': entity_titles_valid,\n",
        "    'Predicted Category': predicted_categories_valid,\n",
        "    'Actual Category': actual_categories_valid\n",
        "})\n",
        "\n",
        "validation_results.to_excel('validation_results_with_tuning.xlsx', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRuxuuWEzogR",
        "outputId": "416be746-027a-41d8-964a-4063cbdafd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
            "Validation Accuracy with Best Hyperparameters: 0.7287128712871287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_60A3v3g7UXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load validation results\n",
        "validation_results = pd.read_excel('predicted_categories.xlsx')\n",
        "\n",
        "# Filter rows where predicted category is different from actual category\n",
        "wrong_predictions = validation_results[validation_results['Predicted Category'] != validation_results['Actual Category']]\n",
        "\n",
        "# Save the wrongly predicted categories to an Excel file\n",
        "wrong_predictions.to_excel('wrong_predictions.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "NPb9065a7Uki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}